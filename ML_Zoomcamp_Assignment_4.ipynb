{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIHyaRlkbFgN6d5mWcrGku",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsalami-092/Blessing-ML-Zoomcamp-2025/blob/main/ML_Zoomcamp_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWujuU1blgwC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, recall_score, precision_recall_curve\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'"
      ],
      "metadata": {
        "id": "Ob6KABhn1Ze6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget $data"
      ],
      "metadata": {
        "id": "HWZ_TH4p1ev-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "zEwU2Rum1oZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "YQ5yNqhm1ylo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_var = list(df.dtypes[df.dtypes == 'object'].index)\n",
        "\n",
        "cat_var"
      ],
      "metadata": {
        "id": "kftxuEdH5GMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_var = list(df.dtypes[df.dtypes != 'object'].index)\n",
        "\n",
        "num_var"
      ],
      "metadata": {
        "id": "XSrdMRFh8dFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " df.isna().sum()"
      ],
      "metadata": {
        "id": "EjQyfqcC9MPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in cat_var:\n",
        "  df[i] = df[i].fillna('NA')"
      ],
      "metadata": {
        "id": "TB0LtfwpVmfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for z in num_var:\n",
        "  df[z] = df[z].fillna(0)"
      ],
      "metadata": {
        "id": "h57iQgR_ZFBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "KM3mcGYhbHhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
        "df_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=1)\n",
        "\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "y_train = df_train.converted.values\n",
        "y_val = df_val.converted.values\n",
        "y_test = df_test.converted.values\n",
        "\n",
        "del df_train['converted']\n",
        "del df_val['converted']\n",
        "del df_test['converted']"
      ],
      "metadata": {
        "id": "NWFyhMdPbKb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1: ROC AUC feature importance**\n",
        "* ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
        "\n",
        "* For each numerical variable, use it as score (aka prediction) and compute the AUC with the y variable as ground truth.\n",
        "* Use the training dataset for that\n",
        "* If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
        "\n",
        "* (e.g. -df_train['balance'])\n",
        "\n",
        "* AUC can go below 0.5 if the variable is negatively correlated with the target variable. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
        "\n",
        "* Which numerical variable (among the following 4) has the highest AUC?\n",
        "\n",
        "* lead_score\n",
        "* number_of_courses_viewed\n",
        "* interaction_count\n",
        "* annual_income"
      ],
      "metadata": {
        "id": "IBqdxUZYkVMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score = {}\n",
        "\n",
        "for i in ['lead_score', 'number_of_courses_viewed', 'interaction_count', 'annual_income']:\n",
        "    auc = roc_auc_score(df_train_full['converted'], df_train_full[i])\n",
        "\n",
        "    if auc < 0.5:\n",
        "      auc = roc_auc_score(df_train_full['converted'], -df_train_full[i])\n",
        "\n",
        "    auc_score[i] = auc\n",
        "\n",
        "auc_score = {k: float(v) for k, v in auc_score.items()}.items()\n",
        "auc_score = sorted(auc_score, key=lambda x: x[1], reverse=True)"
      ],
      "metadata": {
        "id": "9DN_MW8NcNpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score"
      ],
      "metadata": {
        "id": "1gzV4kEyeK5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: Training the model**\n",
        "* Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
        "\n",
        "* LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
        "* What's the AUC of this model on the validation dataset? (round to 3 digits)"
      ],
      "metadata": {
        "id": "kXcNHG3NhR3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_var.remove('converted')"
      ],
      "metadata": {
        "id": "fNFZv1dAh2S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dv = DictVectorizer(sparse=False)\n",
        "\n",
        "train_dict = df_train[cat_var + num_var].to_dict(orient='records')\n",
        "X_train = dv.fit_transform(train_dict)"
      ],
      "metadata": {
        "id": "5hOxIjonjygP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "N7LRHsbaid1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dict = df_val[cat_var + num_var].to_dict(orient='records')\n",
        "X_val = dv.transform(val_dict)"
      ],
      "metadata": {
        "id": "5JaG644WijvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yval_preds = model.predict(X_val)"
      ],
      "metadata": {
        "id": "PudzusK0itKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc = roc_auc_score(y_val, yval_preds)\n",
        "\n",
        "round(float(auc), 3)"
      ],
      "metadata": {
        "id": "fh2hIaQPixUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_val, yval_preds)"
      ],
      "metadata": {
        "id": "-NMxrholjZkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "\n",
        "plt.plot(fpr, tpr, label='model')\n",
        "plt.plot([0, 1], [0, 1], label='random', linestyle='--')\n",
        "#plt.plot(df_rand.fpr, df_rand.tpr, label='random')\n",
        "#plt.plot(df_ideal.fpr, df_ideal.tpr, label='ideal')\n",
        "\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "wI8GfHfXj0YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: Precision and Recall**\n",
        "* Now let's compute precision and recall for our model.\n",
        "\n",
        "* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
        "For each threshold, compute precision and recall\n",
        "\n",
        "* Plot them at which threshold precision and recall curves intersect?"
      ],
      "metadata": {
        "id": "fAMEhXYP2jhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(0, 11, 0.01)"
      ],
      "metadata": {
        "id": "3POLC8y4j4fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(solver='liblinear', C=1, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "yval_probs = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "thresholds = np.arange(0.0, 1.01, 0.01)\n",
        "precisions, recalls = [], []\n",
        "\n",
        "for t in thresholds:\n",
        "    yval_preds = (yval_probs >= t).astype(int)\n",
        "    precisions.append(precision_score(y_val, yval_preds))\n",
        "    recalls.append(recall_score(y_val, yval_preds))"
      ],
      "metadata": {
        "id": "z4JxlvCYPiMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(thresholds, precisions, label='Precision')\n",
        "plt.plot(thresholds, recalls, label='Recall')\n",
        "\n"
      ],
      "metadata": {
        "id": "7a621vr07sCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff = np.abs(np.array(precisions) - np.array(recalls))\n",
        "\n",
        "np.where(diff < 0.01)"
      ],
      "metadata": {
        "id": "eWSwoJ7YZPs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see that the curves intercepted more than once\n",
        "diff = np.abs(np.array(precisions) - np.array(recalls))\n",
        "close_points = np.where(diff < 0.01)[0]\n",
        "\n",
        "if len(close_points) > 0:\n",
        "    idx = close_points[0]\n",
        "else:\n",
        "    idx = np.argmin(diff)\n",
        "\n",
        "best_threshold = thresholds[idx]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(thresholds, precisions, label='Precision')\n",
        "plt.plot(thresholds, recalls, label='Recall')\n",
        "plt.axvline(best_threshold, color='red', linestyle='--', label=f'First Intersection at {best_threshold:.2f}')\n",
        "plt.scatter(best_threshold, precisions[idx], color='red')\n",
        "\n",
        "plt.xlabel('Probability Threshold')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Precision and Recall vs Threshold')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Lowest intersection threshold = {best_threshold:.2f}\")\n",
        "print(f\"Precision = {precisions[idx]:.3f}, Recall = {recalls[idx]:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fdInCbhNDAwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4: F₁ score\n",
        "\n",
        "Precision and recall are often in conflict — when one grows, the other tends to go down.  \n",
        "To balance both we use the **F₁ score**, the harmonic mean of precision (**P**) and recall (**R**):\n",
        "\n",
        "$$\n",
        "F_1 = \\frac{2 \\cdot P \\cdot R}{P + R}\n",
        "$$\n",
        "\n",
        "Where:  \n",
        "- **P** = Precision  \n",
        "- **R** = Recall  \n",
        "\n",
        "Compute **F₁** for all thresholds from **0.00** to **1.00** (step **0.01**).  \n",
        "Which threshold gives the **maximum F₁**?\n"
      ],
      "metadata": {
        "id": "I1gAm1tb05ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(solver='liblinear', C=1, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "yval_probs = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "thresholds = np.arange(0.0, 1.01, 0.01)\n",
        "precisions, recalls, f1 = [], [], []\n",
        "\n",
        "for t in thresholds:\n",
        "    yval_preds = (yval_probs >= t).astype(int)\n",
        "    precision = precision_score(y_val, yval_preds)\n",
        "    recall = recall_score(y_val, yval_preds)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    if (precision + recall) == 0:\n",
        "        f1.append(0)\n",
        "    else:\n",
        "        f1.append(2 * (precision * recall) / (precision + recall))"
      ],
      "metadata": {
        "id": "Ics7-uHM1Jw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = np.array(f1)\n",
        "idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[idx]\n",
        "best_f1 = f1_scores[idx]\n",
        "\n",
        "print(f\"Best threshold: {best_threshold:.2f}, Best F1: {best_f1:.3f}\")\n"
      ],
      "metadata": {
        "id": "kcRbAi2A6ghc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 Question 5: 5-Fold Cross-Validation\n",
        "\n",
        "Use the **KFold** class from **Scikit-Learn** to evaluate our model on 5 different folds.\n",
        "\n",
        "- Use the following parameters for KFold:  \n",
        "  `KFold(n_splits=5, shuffle=True, random_state=1)`\n",
        "\n",
        "- Iterate over different folds of `df_full_train`\n",
        "- Split the data into **train** and **validation** sets\n",
        "- Train the model on the train set using:  \n",
        "  `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
        "- Use **AUC (Area Under the Curve)** to evaluate the model on the validation set\n",
        "\n",
        "**Question:**  \n",
        "👉 How large is the **standard deviation** of the AUC scores across the different folds?\n"
      ],
      "metadata": {
        "id": "69Eebvlh915_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits = 5\n",
        "\n",
        "scores = []\n",
        "\n",
        "kfold =KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
        "\n",
        "\n",
        "for train_idx, val_idx in tqdm(kfold.split(df_train_full), total = n_splits):\n",
        "    df_train = df_train_full.iloc[train_idx]\n",
        "    df_val = df_train_full.iloc[val_idx]\n",
        "\n",
        "    y_train = df_train.converted.values\n",
        "    y_val = df_val.converted.values\n",
        "\n",
        "\n",
        "    dv = DictVectorizer(sparse=False)\n",
        "    train_dict = df_train[cat_var + num_var].to_dict(orient='records')\n",
        "    X_train = dv.fit_transform(train_dict)\n",
        "\n",
        "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    val_dict = df_val[cat_var + num_var].to_dict(orient='records')\n",
        "    X_val = dv.transform(val_dict)\n",
        "    yval_preds = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "\n",
        "    auc = roc_auc_score(y_val, yval_preds)\n",
        "    scores.append(auc)\n",
        "\n",
        "    print(\"Mean AUC: %.3f ± %.3f\" % (np.mean(scores), np.std(scores)))"
      ],
      "metadata": {
        "id": "h3WxKPbO8O-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚙️ Question 6: Hyperparameter Tuning\n",
        "\n",
        "Now let's use **5-Fold Cross-Validation** to find the best parameter **C**.\n",
        "\n",
        "- Iterate over the following values of **C**:  \n",
        "  `[0.000001, 0.001, 1]`\n",
        "- Initialize **KFold** with the same parameters as before:  \n",
        "  `KFold(n_splits=5, shuffle=True, random_state=1)`\n",
        "- Use these parameters for the model:  \n",
        "  `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
        "- For each value of **C**, compute:\n",
        "  - The **mean AUC score** across all folds  \n",
        "  - The **standard deviation** of the AUC scores  \n",
        "\n",
        "(👉 Round both the mean and standard deviation to **3 decimal digits**.)\n",
        "\n",
        "**Question:**  \n",
        "Which value of **C** gives the **best mean AUC score**?\n"
      ],
      "metadata": {
        "id": "t1xiOEbeNshh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits = 5\n",
        "\n",
        "results = []\n",
        "\n",
        "for C in [0.000001, 0.001, 1]:\n",
        "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
        "    scores = []\n",
        "\n",
        "    for train_idx, val_idx in tqdm(kfold.split(df_train_full), total=n_splits):\n",
        "        df_train = df_train_full.iloc[train_idx]\n",
        "        df_val = df_train_full.iloc[val_idx]\n",
        "\n",
        "        y_train = df_train.converted.values\n",
        "        y_val = df_val.converted.values\n",
        "\n",
        "        dv = DictVectorizer(sparse=False)\n",
        "        train_dict = df_train[cat_var + num_var].to_dict(orient='records')\n",
        "        X_train = dv.fit_transform(train_dict)\n",
        "\n",
        "        model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        val_dict = df_val[cat_var + num_var].to_dict(orient='records')\n",
        "        X_val = dv.transform(val_dict)\n",
        "        yval_pred = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        auc = roc_auc_score(y_val, yval_pred)\n",
        "        scores.append(auc)\n",
        "\n",
        "    mean_auc = np.mean(scores)\n",
        "    std_auc = np.std(scores)\n",
        "\n",
        "    print(f'C={C}  {mean_auc:.3f} ± {std_auc:.3f}')\n",
        "    results.append({'C': C, 'mean_auc': round(mean_auc, 3), 'std_auc': round(std_auc, 3)})\n",
        "\n",
        "results\n"
      ],
      "metadata": {
        "id": "vTsRfYJKS4t3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}